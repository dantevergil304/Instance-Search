from keras import optimizers
from keras.engine import Model
from keras.layers import Flatten, Dense, Input, Dropout
from keras_vggface.vggface import VGGFace
from keras.models import load_model, model_from_json
from keras.regularizers import l2
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint

import cv2
import numpy as np


def create_regularized_model(model, WEIGHT_DECAY):
    model.save_weights("tmp.h5")

    # optionally do some other modifications
    # (freezing layers, adding convolutions etc.)

    regularizer = l2(WEIGHT_DECAY / 2)
    for layer in model.layers:
        if layer.trainable is False:
            continue
        for attr in ['kernel_regularizer']:
            if hasattr(layer, attr) and layer.trainable:
                setattr(layer, attr, regularizer)

    out = model_from_json(model.to_json())
    out.load_weights("tmp.h5", by_name=True)

    return out


def split_train_val(training_data):
    # with open(training_path, 'rb') as f:
    #  X, y = pickle.load(f)

    X, y = training_data

    num_pos = sum([val for val in y])
    num_neg = len(y) - num_pos

    # k = np.array(list(zip(X, y)))
    # np.random.shuffle(k[:num_pos])
    # np.random.shuffle(k[num_pos:])

    # X = k[:, 0].tolist()
    # y = k[:, 1].tolist()

    X_train = X[:int(num_pos*0.7)] + X[num_pos:num_pos + int(num_neg*0.7)]
    y_train = y[:int(num_pos*0.7)] + y[num_pos:num_pos + int(num_neg*0.7)]

    X_val = X[int(num_pos*0.7):num_pos] + X[num_pos + int(num_neg*0.7):]
    y_val = y[int(num_pos*0.7):num_pos] + y[num_pos + int(num_neg*0.7):]

    return X_train, y_train, X_val, y_val


def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """

    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(
                batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)


def fine_tune(train_data, save_path, numStep=None, batchSize=32, eps=10):
    '''
    Parameters:
    - train_data: [X, Y]
    - eps: num epochs
    Returns:
    - fine-tuned model
    '''
    nb_class = 2

    model = VGGFace(input_shape=(224, 224, 3))

    for layer in model.layers[:-11]:
        layer.trainable = False

    model = create_regularized_model(model, 5e-4)

    fc6_relu = model.get_layer('fc6/relu')
    fc7_relu = model.get_layer('fc7/relu')

    dropout_fc6 = Dropout(0.5)
    dropout_fc7 = Dropout(0.5)

    x = dropout_fc6(fc6_relu.output)
    x = fc7_relu(x)
    x = dropout_fc7(x)
    out = Dense(nb_class, activation='softmax', name='fc8')(x)

    finetune_model = Model(model.input, out)

    for layer in finetune_model.layers:
        print(layer, layer.trainable)

    optimizer = optimizers.SGD(lr=1e-4, momentum=0.9)
    finetune_model.compile(optimizer=optimizer,
                           loss='sparse_categorical_crossentropy',
                           metrics=['accuracy'])

    # Split train validation data
    X_train, y_train, X_val, y_val = split_train_val(train_data)

    # Convert train data to numpy type
    #X_train_crop = cropListImage(X_train, 224)
    train_images = np.reshape(X_train, (-1, 256, 256, 3))
    train_labels = np.array(y_train)

    # Get center crop 224x224 for validation images
    start_px = int((256 - 224) / 2)
    end_px = int(start_px + 224)
    #X_val_crop = centerCropListImage(X_val, 224)
    val_images = np.reshape(X_val, (-1, 256, 256, 3))
    val_images = val_images[:, start_px:end_px, start_px:end_px, :]
    print(val_images.shape)
    val_labels = np.array(y_val)

    train_datagen = ImageDataGenerator(horizontal_flip=True)
    train_batches = train_datagen.flow(
        train_images, train_labels, batch_size=batchSize)
    train_crops = crop_generator(train_batches, 224)

    mcp_save = ModelCheckpoint(
        save_path, save_best_only=True, monitor='val_loss', mode='min')
    reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=5)
    if numStep is None:
        numStep = len(train_images)/batchSize
    finetune_model.fit_generator(train_crops, validation_data=(
        val_images, val_labels), steps_per_epoch=numStep, verbose=1, epochs=eps, callbacks=[mcp_save, reduce_lr])

    return finetune_model


def extract_face_features(model_path, faces_list):
    model = load_model(model_path)

    feature_extractor = Model(model.input, model.get_layer('fc6').output)

    resized_faces_list = []
    for face in faces_list:
        resized_face = cv2.resize(face, (224, 224))
        resized_faces_list.append(resized_face)

    X = np.reshape(resized_faces_list, (-1, 224, 224, 3))

    return feature_extractor.predict(X, batch_size=20, verbose=1)
