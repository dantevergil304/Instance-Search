from keras import optimizers
from keras.engine import Model
from keras.layers import Flatten, Dense, Input, Dropout
from keras_vggface.vggface import VGGFace
from keras.models import load_model, model_from_json
from keras.regularizers import l2
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard
from keras_vggface import utils
from keras import backend as K

import cv2
import numpy as np
import pickle
import sys
import os
import tensorflow as tf


def create_regularized_model(model, WEIGHT_DECAY):
    model.save_weights("tmp.h5")

    # optionally do some other modifications
    # (freezing layers, adding convolutions etc.)

    regularizer = l2(WEIGHT_DECAY / 2)
    for layer in model.layers:
        if layer.trainable is False:
            continue
        for attr in ['kernel_regularizer']:
            if hasattr(layer, attr) and layer.trainable:
                setattr(layer, attr, regularizer)

    model_json = model.to_json()
    K.clear_session()
    out = model_from_json(model_json)
    out.load_weights("tmp.h5", by_name=True)

    return out


def split_train_val(training_data):
    # with open(training_path, 'rb') as f:
    #  X, y = pickle.load(f)

    X, y = training_data

    num_pos = sum([val for val in y])
    num_neg = len(y) - num_pos

    # k = np.array(list(zip(X, y)))
    # np.random.shuffle(k[:num_pos])
    # np.random.shuffle(k[num_pos:])

    # X = k[:, 0].tolist()
    # y = k[:, 1].tolist()

    X_train = X[:int(num_pos*0.7)] + X[num_pos:num_pos + int(num_neg*0.7)]
    y_train = y[:int(num_pos*0.7)] + y[num_pos:num_pos + int(num_neg*0.7)]

    X_val = X[int(num_pos*0.7):num_pos] + X[num_pos + int(num_neg*0.7):]
    y_val = y[int(num_pos*0.7):num_pos] + y[num_pos + int(num_neg*0.7):]

    return X_train, y_train, X_val, y_val


def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """

    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros(
            (batch_x.shape[0], crop_length, crop_length, 3), dtype=np.float64)
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(
                batch_x[i], (crop_length, crop_length))

            if np.random.rand() >= 0.5:
                batch_crops[i] = cv2.flip(batch_crops[i], 1)

        batch_crops = utils.preprocess_input(batch_crops, version=1)
        # for img in batch_crops:
        #     cv2.imshow('fig', img)
        #     cv2.waitKey()
        #     cv2.destroyAllWindows()
        yield (batch_crops, batch_y)


def ImageGeneratorVGGFace(X, y, batch_size):
    # Params:
    # - X: list of face images with different shapes
    # - y: list of labels
    while True:
        batchIdx = np.random.choice(len(X), size=batch_size)
        batchX = []
        batchY = []

        # rescale so that the smaller of width and height is 256
        for idx in batchIdx:
            img = X[idx]
            label = y[idx]

            height, width, _ = img.shape
            ratio = width / height
            width = 256 if width < height else 256*ratio
            height = width / ratio

            img = cv2.resize(img, (int(width), int(height)))

            # cv2.imshow('figure', img)
            # cv2.waitKey()
            # cv2.destroyAllWindows()

            batchX.append(img)
            batchY.append(label)

        batchX = np.array(batchX)
        batchY = np.array(batchY)

        yield (batchX, batchY)


def fine_tune(train_data, save_path, numStep=None, batchSize=32, eps=10):
    '''
    Parameters:
    - train_data: [X, Y]
    - eps: num epochs
    Returns:
    - fine-tuned model
    '''
    nb_class = 2

    model = VGGFace(input_shape=(224, 224, 3))

    for layer in model.layers[:-11]:
        layer.trainable = False

    model = create_regularized_model(model, 5e-4)

    fc6_relu = model.get_layer('fc6/relu')
    fc7_relu = model.get_layer('fc7/relu')

    dropout_fc6 = Dropout(0.5)
    dropout_fc7 = Dropout(0.5)

    x = dropout_fc6(fc6_relu.output)
    x = fc7_relu(x)
    x = dropout_fc7(x)
    out = Dense(nb_class, activation='softmax', name='fc8')(x)

    finetune_model = Model(model.input, out)

    for layer in finetune_model.layers:
        print(layer, layer.trainable)

    optimizer = optimizers.SGD(lr=1e-4, momentum=0.9)
    finetune_model.compile(optimizer=optimizer,
                           loss='sparse_categorical_crossentropy',
                           metrics=['accuracy'])

    # Split train validation data
    X_train, y_train, X_val, y_val = split_train_val(train_data)

    # Convert train data to numpy type
    #X_train_crop = cropListImage(X_train, 224)
    # train_images = np.reshape(X_train, (-1, 256, 256, 3))
    #train_labels = np.array(y_train)

    # Get center crop 224x224 for validation images
    # start_px = int((256 - 224) / 2)
    # end_px = int(start_px + 224)
    #X_val_crop = centerCropListImage(X_val, 224)
    # val_images = np.reshape(X_val, (-1, 256, 256, 3))
    # val_images = val_images[:, start_px:end_px, start_px:end_px, :]
    val_images = []
    for img in X_val:
        height, width, _ = img.shape
        ratio = width / height
        width = 256 if width < height else 256*ratio
        height = width / ratio

        img = cv2.resize(img, (int(width), int(height)))

        # center crop
        sr = int((height - 224) / 2)
        sc = int((width - 224) / 2)

        val_images.append(img[sr:sr+224, sc:sc+224, :])
    val_images = np.array(val_images, dtype=np.float64)
    val_images = utils.preprocess_input(val_images, version=1)
    val_labels = np.array(y_val)

    # train_datagen = ImageDataGenerator(horizontal_flip=True)
    # train_batches = train_datagen.flow(
    #     train_images, train_labels, batch_size=batchSize)
    # train_crops = crop_generator(train_batches, 224)
    train_batches = ImageGeneratorVGGFace(
        X_train, y_train, batch_size=batchSize)
    train_crops = crop_generator(train_batches, 224)

    mcp_save = ModelCheckpoint(
        save_path, save_best_only=True, monitor='val_loss', mode='min')
    reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=5)
    tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,
                              write_graph=True, write_images=False)
    if numStep is None:
        numStep = len(X_train)/batchSize
    finetune_model.fit_generator(train_crops, validation_data=(
        val_images, val_labels), steps_per_epoch=numStep, verbose=1, epochs=eps, callbacks=[mcp_save, reduce_lr, tensorboard])

    return finetune_model


def extract_feature_from_face_list(model_path, faces_list):
    model = load_model(model_path)

    feature_extractor = Model(model.input, model.get_layer('fc6').output)

    resized_faces_list = []
    for face in faces_list:
        resized_face = cv2.resize(face, (224, 224))
        resized_faces_list.append(resized_face)

    X = np.reshape(resized_faces_list, (-1, 224, 224, 3))

    return feature_extractor.predict(X, batch_size=20, verbose=1)


def setRandomSeed(seed=42):
    np.random.seed(seed)
    tf.set_random_seed(seed)


if __name__ == '__main__':
    os.environ['CUDA_VISIBLE_DEVICES'] = sys.argv[1]
    setRandomSeed()
    with open('../data/training_data/vgg_data/config_fc7_2018_linear_svm_vgg16_pool5_gap/chelsea/training_data.pkl', 'rb') as f:
        data = pickle.load(f)
    fine_tune(data, './fine_tuned_model.h5',
              numStep=None, batchSize=20, eps=20)
